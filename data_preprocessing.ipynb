{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - CasierVert952\n",
    "\n",
    "This is a part of the [analysis.ipynb](analysis.ipynb) that performs the preprocessing of the data from two beers ratings websites (BeerAdvocate and RateBeer).\n",
    "\n",
    "> *For improved readability, the complex and long functions developed for this analysis have been moved to ```helpers.py```. We import these functions into the relevant cells as needed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the basic requiered libraries\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# path variables\n",
    "BA_DATA_PATH = \"data/BeerAdvocate/\"\n",
    "RB_DATA_PATH = \"data/RateBeer/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformation of TXT ratings files to CSV\n",
    "\n",
    "A download of the ```ratings.csv``` files for both datasets is available with the following links (~2.5 GB each):\n",
    "\n",
    "- For BeerAdvocate (BA) : [here](https://coursedingler.ch/data/BA/ratings.csv)\n",
    "- For RateBeer (RB) : [here](https://coursedingler.ch/data/RB/ratings.csv)\n",
    "\n",
    "The following cell should **NOT** be executed, it only shows how the ```ratings.csv``` for each dataset were generated.\n",
    "\n",
    "It takes around 15 minutes to generate both files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "# code to generate ratings.csv for each website\n",
    "\n",
    "from helpers import txt_to_csv\n",
    "\n",
    "file_txt = 'ratings.txt'\n",
    "file_csv = 'ratings.csv'\n",
    "\n",
    "txt_to_csv(BA_DATA_PATH + file_txt, BA_data_path + file_csv, \"BA\")\n",
    "txt_to_csv(RB_DATA_PATH + file_txt, RB_data_path + file_csv, \"RB\")\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before continuing further, make sure you placed the ```ratings.csv``` files in the ```BeerAdvocate``` and ```RateBeer``` folders. Your folder ```data``` should look like this :**\n",
    "```\n",
    "data/\n",
    "├── BeerAdvocate\n",
    "│   ├── beers.csv\n",
    "│   ├── breweries.csv\n",
    "│   ├── users.csv\n",
    "│   └── ratings.csv\n",
    "│\n",
    "└── RateBeer\n",
    "    ├── beers.csv\n",
    "    ├── breweries.csv\n",
    "    ├── users.csv\n",
    "    └── ratings.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Loading CSV data\n",
    "Let first import the data in CSV format for the two datasets, the users, the beers and the breweries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframes for the BA dataset\n",
    "BA_beers = pd.read_csv(BA_DATA_PATH + 'beers.csv')\n",
    "BA_breweries = pd.read_csv(BA_DATA_PATH + 'breweries.csv')\n",
    "BA_users = pd.read_csv(BA_DATA_PATH + 'users.csv')\n",
    "\n",
    "# create Dataframes for the RB dataset\n",
    "RB_beers = pd.read_csv(RB_DATA_PATH + 'beers.csv')\n",
    "RB_breweries = pd.read_csv(RB_DATA_PATH + 'breweries.csv')\n",
    "RB_users = pd.read_csv(RB_DATA_PATH + 'users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading of BA ratings ended in 77.73346710205078 seconds.\n",
      "Reading of RB ratings ended in 64.72716903686523 seconds.\n"
     ]
    }
   ],
   "source": [
    "# create Dataframes for the BA ratings file\n",
    "s_time = time.time()\n",
    "BA_rating = pd.read_csv(BA_DATA_PATH + 'ratings.csv')\n",
    "e_time = time.time()\n",
    "print(\"Reading of BA ratings ended in \" + str(e_time - s_time) + \" seconds.\")\n",
    "\n",
    "# create Dataframes for the RB ratings file\n",
    "s_time = time.time()\n",
    "RB_rating = pd.read_csv(RB_DATA_PATH + 'ratings.csv')\n",
    "e_time = time.time()\n",
    "print(\"Reading of RB ratings ended in \" + str(e_time - s_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merging data\n",
    "\n",
    "#### 4.1 Dropping and renaming columns\n",
    "\n",
    "Here, the columns that are not needed are dropped and some of them will be recovered during the merging phase. The columns are renamed to avoid colisions during the merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import ratings_dict\n",
    "\n",
    "# removing not needed columns\n",
    "BA_rating.drop(columns=[\"text\", \"review\"], inplace=True)\n",
    "RB_rating.drop(columns=[\"text\"], inplace=True)\n",
    "\n",
    "# removing columns that will be recovered when merging\n",
    "BA_rating.drop(columns=[\"brewery_name\", \"style\", \"beer_name\", \"user_name\", \"abv\"], inplace=True)\n",
    "RB_rating.drop(columns=[\"brewery_name\", \"style\", \"beer_name\", \"user_name\", \"abv\"], inplace=True)\n",
    "\n",
    "# renaming the columns as define by \"ratings_dict\"\n",
    "BA_rating.rename(columns=ratings_dict, inplace=True)\n",
    "RB_rating.rename(columns=ratings_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Merging with beers' data\n",
    "Here, the ```beers``` data is merged with the ```ratings``` data for both websites (BA & RB) to create a bigger Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import beers_dict\n",
    "\n",
    "# merging with the beers's data\n",
    "BA_merged = pd.merge(BA_rating, BA_beers, on=[\"beer_id\", \"brewery_id\"], how=\"inner\")\n",
    "RB_merged = pd.merge(RB_rating, RB_beers, on=[\"beer_id\", \"brewery_id\"], how=\"inner\")\n",
    "\n",
    "# renaming the columns as define by \"beers_dict\"\n",
    "BA_merged.rename(columns=beers_dict, inplace=True)\n",
    "RB_merged.rename(columns=beers_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Merging with breweries' data\n",
    "Here, the ```breweries``` data is added to the big Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import breweries_dict\n",
    "\n",
    "# merging with the breweries's data\n",
    "BA_merged = pd.merge(BA_merged, BA_breweries, left_on=\"brewery_id\", right_on=\"id\", how=\"inner\")\n",
    "RB_merged = pd.merge(RB_merged, RB_breweries, left_on=\"brewery_id\", right_on=\"id\", how=\"inner\")\n",
    "\n",
    "# dropping the duplicate columns\n",
    "BA_merged.drop(columns=[\"id\", \"name\"], inplace=True)\n",
    "RB_merged.drop(columns=[\"id\", \"name\"], inplace=True)\n",
    "\n",
    "# renaming the columns as define by \"breweries_dict\"\n",
    "BA_merged.rename(columns=breweries_dict, inplace=True)\n",
    "RB_merged.rename(columns=breweries_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Merging with users' data\n",
    "Finally, the ```users``` data is added to the big Dataframe to create two dataframes (BA_merged & RB_merged) containing everything for easier manipulation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import users_dict\n",
    "\n",
    "# Merging with the users's data\n",
    "BA_merged = pd.merge(BA_merged, BA_users, on=[\"user_id\"], how=\"inner\")\n",
    "RB_merged = pd.merge(RB_merged, RB_users, on=[\"user_id\"], how=\"inner\")\n",
    "\n",
    "# Renaming the columns as define by \"users_dict\"\n",
    "BA_merged.rename(columns=users_dict, inplace=True)\n",
    "RB_merged.rename(columns=users_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Changing dates format\n",
    "\n",
    "The format of the dates fields were initialy in the timestamp format. Here they get converted in a human readable format. Then, as only the month and the year will be needed for the analysis that will be performed, the precise day of the month is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the format of the rating date to the format \"Month-Year\" for both websites\n",
    "BA_cleaned = BA_merged\n",
    "BA_cleaned[\"rating_date\"] = pd.to_datetime(BA_cleaned[\"rating_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "RB_cleaned = RB_merged\n",
    "RB_cleaned[\"rating_date\"] = pd.to_datetime(RB_cleaned[\"rating_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# changing the format of the user_join date to the format \"Month-Year\" for both websites\n",
    "BA_cleaned = BA_merged\n",
    "BA_cleaned[\"user_join_date\"] = pd.to_datetime(BA_cleaned[\"user_join_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "RB_cleaned = RB_merged\n",
    "RB_cleaned[\"user_join_date\"] = pd.to_datetime(RB_cleaned[\"user_join_date\"], unit='s').dt.strftime(\"%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Extracting the country and states\n",
    "\n",
    "Since the analysis that will be performed later on will focus on american states, the user's and breweries' location fields get divided in ```country``` and ```state```. The state is filled with ```nan``` if not present (for European countries for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For BeerAdvocate\n",
    "# spliting the \"user_location\" in country and state fields \n",
    "split_locations = BA_cleaned['user_location'].str.split(',', expand=True)\n",
    "BA_cleaned['user_country'] = split_locations[0].str.strip()\n",
    "BA_cleaned['user_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan\n",
    "\n",
    "# spliting the \"breweries_location\" in country and state fields\n",
    "split_locations = BA_cleaned['breweries_location'].str.split(',', expand=True)\n",
    "BA_cleaned['breweries_country'] = split_locations[0].str.strip()\n",
    "BA_cleaned['breweries_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan\n",
    "\n",
    "\n",
    "## For RateBeer\n",
    "# spliting the \"user_location\" in country and state fields\n",
    "split_locations = RB_cleaned['user_location'].str.split(',', expand=True)\n",
    "RB_cleaned['user_country'] = split_locations[0].str.strip()\n",
    "RB_cleaned['user_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan\n",
    "\n",
    "# spliting the \"breweries_location\" in country and state fields\n",
    "split_locations = RB_cleaned['breweries_location'].str.split(',', expand=True)\n",
    "RB_cleaned['breweries_country'] = split_locations[0].str.strip()\n",
    "RB_cleaned['breweries_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for better readability, the order of columns is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning new order for BeerAdvocate dataframe\n",
    "BA_new_column_order = [\n",
    "    'rating_date', 'rating_appearance',\n",
    "    'rating_aroma', 'rating_palate', 'rating_taste', 'rating_overall',\n",
    "    'rating', 'beer_id', 'beer_name', 'beer_style', 'beer_nbr_ratings',\n",
    "    'beer_nbr_reviews', 'beer_avg', 'beer_ba_score', 'beer_bros_score',\n",
    "    'beer_abv', 'beer_avg_computed', 'beer_zscore',\n",
    "    'beer_nbr_matched_valid_ratings', 'beer_avg_matched_valid_ratings', 'brewery_id',\n",
    "    'brewery_name', 'breweries_location', 'breweries_country', 'breweries_state', 'breweries_nbr_beers',\n",
    "    'user_id', 'user_nbr_ratings', 'user_nbr_reviews', 'user_name', 'user_join_date',\n",
    "    'user_location', 'user_country', 'user_state'\n",
    "]\n",
    "\n",
    "# assigning new order for RateBeer dataframe\n",
    "RB_new_column_order = [ \n",
    "    'rating_date', 'rating_appearance',\n",
    "    'rating_aroma', 'rating_palate', 'rating_taste', 'rating_overall',\n",
    "    'rating', 'beer_id', 'beer_name', 'beer_style', 'beer_nbr_ratings',\n",
    "    'overall_score', 'style_score', 'beer_avg', 'beer_abv',\n",
    "    'beer_avg_computed', 'beer_zscore', 'beer_nbr_matched_valid_ratings',\n",
    "    'beer_avg_matched_valid_ratings', 'brewery_id', 'brewery_name', 'breweries_location',\n",
    "    'breweries_country', 'breweries_state', 'breweries_nbr_beers', 'user_id', 'user_nbr_ratings', 'user_name',\n",
    "    'user_join_date', 'user_location', 'user_country', 'user_state'\n",
    "]\n",
    "\n",
    "# apply new order\n",
    "BA_cleaned = BA_cleaned[BA_new_column_order]\n",
    "RB_cleaned = RB_cleaned[RB_new_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Saving cleaned data\n",
    "\n",
    "The following cell saves the data merged and cleaned in a CSV file. After that step, the two dataframes can be loaded quickly without having to perform the preprocessing step again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data in CSV files\n",
    "BA_cleaned.to_csv(BA_DATA_PATH + 'BA_cleaned.csv', index=False)\n",
    "RB_cleaned.to_csv(RB_DATA_PATH + 'RB_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
