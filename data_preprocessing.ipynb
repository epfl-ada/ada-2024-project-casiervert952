{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - CasierVert952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a part of the [analysis.ipynb](analysis.ipynb) that perform the preprocessing of the data from two beers ratings websites (BeerAdvocate and RateBeer).\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "### 1 Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic requiered libraries\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path variables\n",
    "BA_DATA_PATH = \"data/BeerAdvocate/\"\n",
    "RB_DATA_PATH = \"data/RateBeer/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Transformation of TXT ratings files to CSV\n",
    "\n",
    "You can download the ```ratings.csv``` files for both dataset with the following links (~2GB each):\n",
    "\n",
    "- For BA : [here](https://coursedingler.ch/data/BA/ratings.csv)\n",
    "- For RB : [here](https://coursedingler.ch/data/RB/ratings.csv)\n",
    "\n",
    "The following cell should **NOT** be executed, it only shows how the ```ratings.csv``` for each dataset were generated.\n",
    "\n",
    "It take around 19 minutes to generate the BA ratings file and 14 minutes for the RB one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from helpers import txt_to_csv\n",
    "\n",
    "file_txt = 'ratings.txt'\n",
    "file_csv = 'ratings.csv'\n",
    "\n",
    "txt_to_csv(BA_DATA_PATH + file_txt, BA_data_path + file_csv, \"BA\")\n",
    "txt_to_csv(RB_DATA_PATH + file_txt, RB_data_path + file_csv, \"RB\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you have been placed or generated the ```ratings.csv``` files in the ```BeerAdvocate``` and ```RateBeer``` folders as well as all other data files when executing the following cells !**\n",
    "```\n",
    "data/\n",
    "├── BeerAdvocate\n",
    "│   ├── beers.csv\n",
    "│   ├── breweries.csv\n",
    "│   ├── users.csv\n",
    "│   └── ratings.csv\n",
    "│\n",
    "└── RateBeer\n",
    "    ├── beers.csv\n",
    "    ├── breweries.csv\n",
    "    ├── users.csv\n",
    "    └── ratings.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3 Loading CSV data\n",
    "Let first import the data in CSV format for the two datasets, the users, the beers and the breweries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframes for the BA dataset\n",
    "BA_beers = pd.read_csv(BA_DATA_PATH + 'beers.csv')\n",
    "BA_breweries = pd.read_csv(BA_DATA_PATH + 'breweries.csv')\n",
    "BA_users = pd.read_csv(BA_DATA_PATH + 'users.csv')\n",
    "\n",
    "# Create Dataframes for the RB dataset\n",
    "RB_beers = pd.read_csv(RB_DATA_PATH + 'beers.csv')\n",
    "RB_breweries = pd.read_csv(RB_DATA_PATH + 'breweries.csv')\n",
    "RB_users = pd.read_csv(RB_DATA_PATH + 'users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading of BA ratings ended in 31.0752112865448 seconds.\n",
      "Reading of RB ratings ended in 35.75707960128784 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframes for the BA ratings file\n",
    "s_time = time.time()\n",
    "BA_rating = pd.read_csv(BA_DATA_PATH + 'ratings.csv')\n",
    "e_time = time.time()\n",
    "print(\"Reading of BA ratings ended in \" + str(e_time - s_time) + \" seconds.\")\n",
    "\n",
    "# Create Dataframes for the RB ratings file\n",
    "s_time = time.time()\n",
    "RB_rating = pd.read_csv(RB_DATA_PATH + 'ratings.csv')\n",
    "e_time = time.time()\n",
    "print(\"Reading of RB ratings ended in \" + str(e_time - s_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Merging data\n",
    "\n",
    "#### 4.1 Dropping and renaming columns\n",
    "\n",
    "We are dropping the columns that are not needed, some of them will be recovered during the merging phase. The columns are renamed to avoid colisions during the merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import ratings_dict\n",
    "\n",
    "# Removing not needed columns\n",
    "BA_rating.drop(columns=[\"text\", \"review\"], inplace=True)\n",
    "RB_rating.drop(columns=[\"text\"], inplace=True)\n",
    "\n",
    "# Removing columns that will be recovered when merging\n",
    "BA_rating.drop(columns=[\"brewery_name\", \"style\", \"beer_name\", \"user_name\", \"abv\"], inplace=True)\n",
    "RB_rating.drop(columns=[\"brewery_name\", \"style\", \"beer_name\", \"user_name\", \"abv\"], inplace=True)\n",
    "\n",
    "# Renaming the columns as define by \"ratings_dict\"\n",
    "BA_rating.rename(columns=ratings_dict, inplace=True)\n",
    "RB_rating.rename(columns=ratings_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Merging with beers 's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import beers_dict\n",
    "\n",
    "# Merging with the beers's data\n",
    "BA_merged = pd.merge(BA_rating, BA_beers, on=[\"beer_id\", \"brewery_id\"], how=\"inner\")\n",
    "RB_merged = pd.merge(RB_rating, RB_beers, on=[\"beer_id\", \"brewery_id\"], how=\"inner\")\n",
    "\n",
    "# Renaming the columns as define by \"beers_dict\"\n",
    "BA_merged.rename(columns=beers_dict, inplace=True)\n",
    "RB_merged.rename(columns=beers_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Merging with breweries's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import breweries_dict\n",
    "\n",
    "# Merging with the breweries's data\n",
    "BA_merged = pd.merge(BA_merged, BA_breweries, left_on=\"brewery_id\", right_on=\"id\", how=\"inner\")\n",
    "RB_merged = pd.merge(RB_merged, RB_breweries, left_on=\"brewery_id\", right_on=\"id\", how=\"inner\")\n",
    "\n",
    "# Dropping the duplicate columns\n",
    "BA_merged.drop(columns=[\"id\", \"name\"], inplace=True)\n",
    "RB_merged.drop(columns=[\"id\", \"name\"], inplace=True)\n",
    "\n",
    "# Renaming the columns as define by \"breweries_dict\"\n",
    "BA_merged.rename(columns=breweries_dict, inplace=True)\n",
    "RB_merged.rename(columns=breweries_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Merging with users's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import users_dict\n",
    "\n",
    "# Merging with the users's data\n",
    "BA_merged = pd.merge(BA_merged, BA_users, on=[\"user_id\"], how=\"inner\")\n",
    "RB_merged = pd.merge(RB_merged, RB_users, on=[\"user_id\"], how=\"inner\")\n",
    "\n",
    "# Renaming the columns as define by \"users_dict\"\n",
    "BA_merged.rename(columns=users_dict, inplace=True)\n",
    "RB_merged.rename(columns=users_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Changing dates format\n",
    "\n",
    "The format of the dates fields were initialy the timestamp format, here we convert it in a human readable format. We only keep the month and the year as it's the only element we need for our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the format of the rating date to the format \"Month-Year\"\n",
    "BA_cleaned = BA_merged\n",
    "BA_cleaned[\"rating_date\"] = pd.to_datetime(BA_cleaned[\"rating_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "RB_cleaned = RB_merged\n",
    "RB_cleaned[\"rating_date\"] = pd.to_datetime(RB_cleaned[\"rating_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Changing the format of the user_join date to the format \"Month-Year\"\n",
    "BA_cleaned = BA_merged\n",
    "BA_cleaned[\"user_join_date\"] = pd.to_datetime(BA_cleaned[\"user_join_date\"], unit='s').dt.strftime(\"%m-%Y\")\n",
    "\n",
    "RB_cleaned = RB_merged\n",
    "RB_cleaned[\"user_join_date\"] = pd.to_datetime(RB_cleaned[\"user_join_date\"], unit='s').dt.strftime(\"%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Extracting the country and states\n",
    "\n",
    "Since our analyses will focus on american states, we have to divide the user location field in ```country``` and ```state```. The state is filled with ```nan``` if not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the \"user_location\" in country and state fields\n",
    "split_locations = BA_cleaned['user_location'].str.split(',', expand=True)\n",
    "BA_cleaned['user_country'] = split_locations[0].str.strip()\n",
    "BA_cleaned['user_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan\n",
    "\n",
    "split_locations = RB_cleaned['user_location'].str.split(',', expand=True)\n",
    "RB_cleaned['user_country'] = split_locations[0].str.strip()\n",
    "RB_cleaned['user_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide breweries location field too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the \"breweries_location\" in country and state fields\n",
    "split_locations = BA_cleaned['breweries_location'].str.split(',', expand=True)\n",
    "BA_cleaned['breweries_country'] = split_locations[0].str.strip()\n",
    "BA_cleaned['breweries_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan\n",
    "\n",
    "split_locations = RB_cleaned['breweries_location'].str.split(',', expand=True)\n",
    "RB_cleaned['breweries_country'] = split_locations[0].str.strip()\n",
    "RB_cleaned['breweries_state'] = split_locations[1].str.strip() if len(split_locations) > 1 else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just changing the order of the columns for a better visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_new_column_order = [\n",
    "    'rating_date', 'rating_appearance',\n",
    "    'rating_aroma', 'rating_palate', 'rating_taste', 'rating_overall',\n",
    "    'rating', 'beer_id', 'beer_name', 'beer_style', 'beer_nbr_ratings',\n",
    "    'beer_nbr_reviews', 'beer_avg', 'beer_ba_score', 'beer_bros_score',\n",
    "    'beer_abv', 'beer_avg_computed', 'beer_zscore',\n",
    "    'beer_nbr_matched_valid_ratings', 'beer_avg_matched_valid_ratings', 'brewery_id',\n",
    "    'brewery_name', 'breweries_location', 'breweries_country', 'breweries_state', 'breweries_nbr_beers',\n",
    "    'user_id', 'user_nbr_ratings', 'user_nbr_reviews', 'user_name', 'user_join_date',\n",
    "    'user_location', 'user_country', 'user_state'\n",
    "]\n",
    "\n",
    "RB_new_column_order = [ \n",
    "    'rating_date', 'rating_appearance',\n",
    "    'rating_aroma', 'rating_palate', 'rating_taste', 'rating_overall',\n",
    "    'rating', 'beer_id', 'beer_name', 'beer_style', 'beer_nbr_ratings',\n",
    "    'overall_score', 'style_score', 'beer_avg', 'beer_abv',\n",
    "    'beer_avg_computed', 'beer_zscore', 'beer_nbr_matched_valid_ratings',\n",
    "    'beer_avg_matched_valid_ratings', 'brewery_id', 'brewery_name', 'breweries_location',\n",
    "    'breweries_country', 'breweries_state', 'breweries_nbr_beers', 'user_id', 'user_nbr_ratings', 'user_name',\n",
    "    'user_join_date', 'user_location', 'user_country', 'user_state'\n",
    "]\n",
    "BA_cleaned = BA_cleaned[BA_new_column_order]\n",
    "RB_cleaned = RB_cleaned[RB_new_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Saving cleaned data\n",
    "\n",
    "The following cell will save the data merged and cleaned in CSV file. After that step, the two dataframes can be loaded quickly without performing the preprocessing step again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned data in CSV files\n",
    "BA_cleaned.to_csv(BA_DATA_PATH + 'BA_cleaned.csv', index=False)\n",
    "RB_cleaned.to_csv(RB_DATA_PATH + 'RB_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
